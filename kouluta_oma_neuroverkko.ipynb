{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OttoTarkka/kouluta-oma-neuroverkko/blob/main/kouluta_oma_neuroverkko.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kouluta oma neuroverkko\n",
        "\n",
        "Tässä notebookin avulla voit kouluttaa oman luokittelijasi.\n",
        "\n",
        "Tiedoston Python-koodi on jaettu soluihin, jotka voi ajaa yksi kerrallaan klikkaamalla solun vasemmassa laidassa olevaa \"play\"-painiketta. Kun teette muokkauksia koodiin, ajakaa sen jälkeen muokattu solu ja kaikki sen jälkeen tulevat solut järjestyksessä, niin koodi toimii oikein.\n",
        "\n",
        "Python-kielessä kaikki risuaidan (#) jälkeen tuleva on kommenttia. Kommenttiriveillä voidaan antaa tietoa koodin toiminnasta, mutta ne eivät ole osa varsinaista suoritettavaa ohjelmaa."
      ],
      "metadata": {
        "id": "6z3NuDfrprZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Tarvittavien pakettien asennus\n",
        "\n",
        "Pythoniin voi asentaa muiden rakentamia ja julkaisemia paketteja. Nämä paketit yksinkertaistavat monia monimutkaisia tehtäviä, eikä meidän esimerkiksi tarvitse rakentaa koko neuroverkkoarkkitehtuuria alusta alkaen.\n",
        "\n",
        "Tätä koodia varten tarvitsemme paketit `transformers`, `datasets` ja `evaluate`."
      ],
      "metadata": {
        "id": "adKOlw8frrlz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t5cMszypelm"
      },
      "outputs": [],
      "source": [
        "# Asennetaan paketit komennolla !pip install\n",
        "!pip install --quiet transformers datasets evaluate\n",
        "\n",
        "# Asentamisen jälkeen paketit pitää vielä aktivoida käyttöön import-komennolla\n",
        "import datasets\n",
        "import transformers\n",
        "import evaluate\n",
        "\n",
        "# pprint eli prettyprint tekee tulosteista kivemman näköisiä\n",
        "from pprint import pprint\n",
        "\n",
        "# Nämä rivit vähentävät ylimääräistä hälyä\n",
        "transformers.utils.logging.set_verbosity_error()\n",
        "datasets.logging.set_verbosity_error()\n",
        "datasets.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Ladataan koulutusdata\n",
        "\n",
        "Ladataan valmiiksi laadittu koulutusdata. Käytetään tähän `datasets`-pakettia, joka lataa datan HuggingFace-palvelusta."
      ],
      "metadata": {
        "id": "kUKGKvnHqKt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vaihtoehtoisia luokitteludatasettejä:\n",
        "# tunteita: \"dair-ai/emotion\"\n",
        "# Lue lisää: https://huggingface.co/datasets/dair-ai/emotion\n",
        "\n",
        "# elokuva-arvosteluja: \"stanfordnlp/imdb\"\n",
        "# Lue lisää: https://huggingface.co/datasets/stanfordnlp/imdb\n",
        "\n",
        "# spämmiviestejä: \"ucirvine/sms_spam\"\n",
        "# Lue lisää: https://huggingface.co/datasets/ucirvine/sms_spam\n",
        "\n",
        "# uutisaiheita: \"fancyzhx/ag_news\"\n",
        "# Lue lisää: https://huggingface.co/datasets/fancyzhx/ag_news\n",
        "\n",
        "# toksisia viestejä: \"mteb/toxic_conversations_50k\"\n",
        "# Lues lisää: https://huggingface.co/datasets/mteb/toxic_conversations_50k\n",
        "\n",
        "# Tässä voit vaihtaa käytettävää datasettiä!\n",
        "DATASET = \"dair-ai/emotion\"\n",
        "\n",
        "dataset = datasets.load_dataset(DATASET)\n",
        "\n",
        "# ====================================================================\n",
        "# Tässä varmistetaan, että datasetin rakenne on sellainen kuin haluamme\n",
        "# Tästä ei tarvitse välittää!\n",
        "def validate_data_strucuture(ds: datasets.DatasetDict):\n",
        "  if not \"test\" in ds.keys():\n",
        "    ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
        "  if not \"validation\" in ds.keys():\n",
        "    if \"valid\" in ds.keys():\n",
        "      ds = ds.rename_column(\"valid\", \"validation\")\n",
        "    elif \"dev\" in ds.keys():\n",
        "      ds = ds.rename_column(\"dev\", \"validation\")\n",
        "    else:\n",
        "      ds_devtest = ds[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
        "      ds = datasets.DatasetDict({\n",
        "          \"train\": ds[\"train\"],\n",
        "          \"validation\": ds_devtest[\"train\"],\n",
        "          \"test\": ds_devtest[\"test\"]\n",
        "      })\n",
        "\n",
        "  # Rename 'sms' column to 'text' if it exists\n",
        "  for split in ds.keys():\n",
        "      if \"sms\" in ds[split].column_names:\n",
        "          ds[split] = ds[split].rename_column(\"sms\", \"text\")\n",
        "\n",
        "  max_train_size = 20000\n",
        "  max_eval_size = 10000\n",
        "  if len(ds[\"train\"]) > max_train_size:\n",
        "    ds[\"train\"] = ds[\"train\"].select(range(max_train_size))\n",
        "\n",
        "  if len(ds[\"validation\"]) > max_eval_size:\n",
        "    ds[\"validation\"] = ds[\"validation\"].select(range(max_eval_size))\n",
        "\n",
        "  if len(ds[\"test\"]) > max_eval_size:\n",
        "    ds[\"test\"] = ds[\"test\"].select(range(max_eval_size))\n",
        "\n",
        "  if not isinstance(ds[\"train\"].features[\"label\"], datasets.ClassLabel):\n",
        "    # Check if label_names column exists\n",
        "    if \"label_text\" in ds[\"train\"].column_names:\n",
        "      unique_labels = ds[\"train\"].unique(\"label_text\")\n",
        "    else:\n",
        "      # Get unique labels from the training set\n",
        "      unique_labels = ds[\"train\"].unique(\"label\")\n",
        "    # Create a ClassLabel object\n",
        "    class_label = datasets.ClassLabel(\n",
        "        num_classes=len(unique_labels),\n",
        "        names=list(sorted(unique_labels))\n",
        "        )\n",
        "    # Cast the labels to the ClassLabel type\n",
        "    for split in ds.keys():\n",
        "      ds[split] = ds[split].cast_column(\"label\", class_label)\n",
        "\n",
        "  return ds\n",
        "\n",
        "dataset = validate_data_strucuture(dataset)\n",
        "# ===================================================================="
      ],
      "metadata": {
        "id": "3lZDBHc7ppI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Katsotaan, miltä lataamamme datasetti näyttää!"
      ],
      "metadata": {
        "id": "fzvOrvMUrQW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)\n",
        "print()\n",
        "print(\"Yksi esimerkki datasta:\")\n",
        "print(dataset[\"train\"][0])"
      ],
      "metadata": {
        "id": "RY-ER5vErVEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datassa tekstin luokat on merkattu numeroilla. Esim 0 = suru,1 = ilo, jne. Muutetaan numerot ihmisluettavaan muotoon."
      ],
      "metadata": {
        "id": "6DlQnP8N7EyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = dataset[\"train\"].features[\"label\"].names\n",
        "print(\"Luokkien nimet:\", label_names)\n",
        "\n",
        "num_labels = len(label_names)\n",
        "id2label = { k: v for k, v in enumerate(label_names) }\n",
        "label2id = { v: k for k, v in enumerate(label_names) }\n",
        "\n",
        "print(\"Luokkien määrä:\", num_labels)\n",
        "print(\"id2label mapping:\", id2label)"
      ],
      "metadata": {
        "id": "JHGjHsNf7I4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Valitaan malli ja tokenisoidaan data\n",
        "\n",
        "Valitaan haluamamme pohjamalli ja ladataan mallille sopiva tokenisoija. Tokenisoidaan data ja muutetaan se numeeriseen muotoon mallin kouluttamista varten."
      ],
      "metadata": {
        "id": "d2yaMXe7unE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vaihtoehtosia malleja:\n",
        "# \"google-bert/bert-base-cased\"     <- englanninkielinen malli\n",
        "# \"FacebookAI/xlm-roberta-base\"     <- monikielinen malli\n",
        "\n",
        "\n",
        "MODEL = \"google-bert/bert-base-cased\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "IG2DtYoRvGWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Katsotaan miltä tokenisoitu teksti näyttää!"
      ],
      "metadata": {
        "id": "yI3Ve7f3vfap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Esimerkki tokenisoidusta lauseesta:\")\n",
        "tokenized_example = tokenizer(\"This is an example sentence\")\n",
        "pprint(tokenized_example[\"input_ids\"])\n",
        "print()\n",
        "print()\n",
        "print(\"Tokenisoitu lause muutettuna takaisin normaaliksi tekstiksi\")\n",
        "pprint(tokenizer.decode(tokenized_example[\"input_ids\"]))\n"
      ],
      "metadata": {
        "id": "b7sIEg4ivgoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenisoidaan koko lataamamme datasetti!"
      ],
      "metadata": {
        "id": "ahtIm0uAxkFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "  return tokenizer(example[\"text\"])\n",
        "\n",
        "dataset = dataset.map(tokenize)"
      ],
      "metadata": {
        "id": "L1e5PSj6xsYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Mallin kouluttaminen\n",
        "\n",
        "Nyt meidän koulutusdatamme on valmiina. Seuraavaksi ladataan pohjamalli, jota aletaan jatkokouluttaa."
      ],
      "metadata": {
        "id": "coct30Pmr0Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_accuracy(outputs_and_labels):\n",
        "    outputs, labels = outputs_and_labels\n",
        "    predictions = outputs.argmax(axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "m5D1eK0FraRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Säädetään koulutusasetukset kuntoon\n",
        "Tässä säädetään asetukset kouluttamista varten.\n",
        "Kokeile muuttaa asetuksia ja katso,\n",
        "miten se vaikuttaa mallin oppimiseen.\n",
        "Kuka kouluttaa parhaan mallin?"
      ],
      "metadata": {
        "id": "5CMOftQi4nIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kokeile muuttaa näitä arvoja ja katso miten se\n",
        "# vaikuttaa mallin oppimiseen\n",
        "max_steps = 1000                # kuinka monella esimerkillä mallia koulutetaan\n",
        "learning_rate = 0.00001         # kuinka nopeasti malli oppii\n",
        "per_device_train_batch_size = 8 # kuinka monta esimerkkiä malli näkee kerralla\n",
        "\n",
        "\n",
        "trainer_args = transformers.TrainingArguments(\n",
        "  output_dir=\"checkpoints\",\n",
        "  eval_strategy=\"steps\",\n",
        "  logging_strategy=\"steps\",\n",
        "  load_best_model_at_end=True,\n",
        "  eval_steps=100,\n",
        "  logging_steps=100,\n",
        "  per_device_eval_batch_size=32,\n",
        "  save_strategy=\"steps\",\n",
        "  save_steps=1000,\n",
        "  max_steps=max_steps,\n",
        "  learning_rate=learning_rate,\n",
        "  per_device_train_batch_size=per_device_train_batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "T13HyLrh2oRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Viimeinkin päästää kouluttamaan!"
      ],
      "metadata": {
        "id": "enKZualc5hzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=trainer_args,\n",
        "    train_dataset=dataset[\"train\"], # treenataan \"train\" datalla\n",
        "    eval_dataset=dataset[\"validation\"], # evaluoidaan \"validation\" datalla\n",
        "    compute_metrics=compute_accuracy,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "3rauYFl45mi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Testataan, kuinka hyvin mallimme toimii!\n",
        "\n",
        "Tässä käytetään testidataa, jota malli ei ole nähnyt lainkaan kouluttamisen aikana."
      ],
      "metadata": {
        "id": "SY4dt3HGA-6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate(dataset[\"test\"])\n",
        "print()\n",
        "print(\"Mallin tarkkuus testidatalla:\", round(eval_results[\"eval_accuracy\"]*100, 2), \"%\")"
      ],
      "metadata": {
        "id": "W3VOmny26WTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Kokeille itse, miten malli toimii!\n",
        "\n",
        "Keksi lauseita ja katso, minkä luokan malli niille ennustaa!\n",
        "Muista, että jos antamasi lauseet ovat hyvin erilaisia kuin koulutusdata, malli ei todennäköisesti toimi kovin hyvin.\n",
        "\n"
      ],
      "metadata": {
        "id": "PWTkJ97rDq7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valmistellaan \"pipeline\", joka tokenisoi annetun tekstin\n",
        "# ja ajaa sen mallin läpi automaattisesti\n",
        "pipe = transformers.pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "pbw6bQL9Dto0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kirjoita oma lauseesi tähän!\n",
        "oma_lause = \"This model is great!\"\n",
        "\n",
        "pred = pipe(oma_lause)\n",
        "print(\"Ennustettu luokka:\", pred[0][\"label\"])\n",
        "print(\"Ennusteen varmuus:\", round(pred[0][\"score\"]*100,2),\"%\")"
      ],
      "metadata": {
        "id": "nTOhvnJ6EIww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}